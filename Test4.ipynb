{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a2da3c-c181-4c95-a1c3-c5cd4ad73daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460ee9cd-3ed5-4a04-b786-d78bb723585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chargement des données (dataset)\n",
    "def load_dataset(test):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(img)\n",
    "            labels.append(folder)  # Le dossier correspond au caractère/nombre\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b530bb-c9b4-4a4e-93b6-440417aa5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Binarisation\n",
    "def binarize_image(image):\n",
    "    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "798d1bfa-2783-4293-884f-26d0142f75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dilatation\n",
    "def dilate_image(binary_image):\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilated = cv2.dilate(binary_image, kernel, iterations=1)\n",
    "    return dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c67ed8-6baa-4071-bb3c-649ab71e2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Suppression des bordures\n",
    "def remove_borders(image):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros_like(image)\n",
    "    cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7f70b5-f014-4ca4-905b-45b5a15754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Détection de la plaque\n",
    "def detect_plate(image):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / float(h)\n",
    "        if 2 < aspect_ratio < 6 and w > 100 and h > 20:\n",
    "            return x, y, w, h\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00844118-5eb5-4e53-812f-0b2bdf1355bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Extraction de la plaque\n",
    "def extract_plate(image, coords):\n",
    "    if coords:\n",
    "        x, y, w, h = coords\n",
    "        plate = image[y:y+h, x:x+w]\n",
    "        return plate\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fcbb4a-e2d4-4c6d-9fe8-2c86dd2af873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Segmentation des caractères\n",
    "def segment_characters(plate):\n",
    "    contours, _ = cv2.findContours(plate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    characters = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if 10 < w < 50 and 20 < h < 60:  # Filtrer selon la taille des caractères\n",
    "            char = plate[y:y+h, x:x+w]\n",
    "            char = cv2.resize(char, (28, 28))  # Redimensionner pour le modèle\n",
    "            characters.append(char)\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1349c2-2772-4bdb-95fe-997e033d4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9. Reconnaissance des caractères (préparation pour le CNN)\n",
    "def preprocess_characters(characters):\n",
    "    chars = np.array([char / 255.0 for char in characters])\n",
    "    chars = chars.reshape(-1, 28, 28, 1)\n",
    "    return chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31313e83-95f0-4437-95ac-02fa9010e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Matrice de convolution (intégrée dans le modèle CNN)\n",
    "def build_resnet_model(num_classes):\n",
    "    inputs = layers.Input(shape=(28, 28, 1))\n",
    "    \n",
    "    # Bloc ResNet simplifié\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Raccourci résiduel\n",
    "    shortcut = layers.Conv2D(32, (1, 1), padding='same')(inputs)\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adda758c-d777-4878-bfaa-b6e227d81ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Intégration et post-traitement\n",
    "def post_process(prediction, char_map):\n",
    "    predicted_chars = [char_map[np.argmax(pred)] for pred in prediction]\n",
    "    return ''.join(predicted_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61680e93-e6c4-4ad7-a8d1-dd9258fed7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    " #12. Création et entraînement du modèle\n",
    "def train_model(images, labels, num_classes):\n",
    "    # Prétraitement\n",
    "    images = images.reshape(-1, 28, 28, 1) / 255.0\n",
    "    label_map = {char: idx for idx, char in enumerate(np.unique(labels))}\n",
    "    inverse_label_map = {idx: char for char, idx in label_map.items()}\n",
    "    labels = np.array([label_map[label] for label in labels])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87c862d1-7d56-40d6-97fc-b2245eba544a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (716,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Séparation des données\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# change selon ton dossier\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Puis maintenant ta séparation fonctionnera :\u001b[39;00m\n\u001b[0;32m      6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(images, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(test)\u001b[0m\n\u001b[0;32m     10\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[0;32m     11\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(folder)  \u001b[38;5;66;03m# Le dossier correspond au caractère/nombre\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39marray(labels)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (716,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "    # Séparation des données\n",
    "dataset_path = \"test\"  # change selon ton dossier\n",
    "images, labels = load_dataset(dataset_path)\n",
    "\n",
    "# Puis maintenant ta séparation fonctionnera :\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426f8c1-a0f8-40a3-9745-a040306115cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Augmentation des données\n",
    "    datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
    "    datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205839c-7122-4c88-8c61-bf806c006022",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Création et entraînement du modèle\n",
    "    model = build_resnet_model(num_classes)\n",
    "    model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=20, validation_data=(X_test, y_test))\n",
    "    \n",
    "    return model, inverse_label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e8100-37d1-4220-be4c-6530af8ad653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Prédiction\n",
    "def predict_plate(image, model, inverse_label_map):\n",
    "    binary = binarize_image(image)\n",
    "    dilated = dilate_image(binary)\n",
    "    cleaned = remove_borders(dilated)\n",
    "    plate_coords = detect_plate(cleaned)\n",
    "    plate = extract_plate(image, plate_coords)\n",
    "    \n",
    "    if plate is not None:\n",
    "        characters = segment_characters(plate)\n",
    "        if characters:\n",
    "            chars_processed = preprocess_characters(characters)\n",
    "            predictions = model.predict(chars_processed)\n",
    "            plate_text = post_process(predictions, inverse_label_map)\n",
    "            return plate_text\n",
    "    return \"No plate detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e24e8-486e-470f-9531-49ab05bbe9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 14. Évaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test accuracy: {accuracy*100:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8154e-fc98-4510-8da4-66d81198993b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb1bea-c91a-4337-bc74-9fb242e2ebde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6536d-d7a2-4266-b81f-4ccf4f0cc4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Remplacez par le chemin de votre dataset\n",
    "    dataset_path = \"path/to/your/dataset\"\n",
    "    images, labels = load_dataset(dataset_path)\n",
    "    \n",
    "    # Entraînement\n",
    "    num_classes = len(np.unique(labels))\n",
    "    model, inverse_label_map = train_model(images, labels, num_classes)\n",
    "    \n",
    "    # Prédiction sur une nouvelle image\n",
    "    test_image = cv2.imread(\"test_plate.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    result = predict_plate(test_image, model, inverse_label_map)\n",
    "    print(f\"Predicted plate: {result}\")\n",
    "    \n",
    "    # Évaluation\n",
    "    X_test = images.reshape(-1, 28, 28, 1) / 255.0\n",
    "    y_test = np.array([inverse_label_map[label] for label in labels])\n",
    "    evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69187c7b-c91f-47b9-80ef-b47e72e47a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d45fb4-1a6d-4090-bf60-ba03d7ad836b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
