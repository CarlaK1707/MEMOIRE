{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les librairies nécessaires\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANPR/plate1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANPR/plate2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANPR/plate3.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Remplacez par vos chemins\u001b[39;00m\n\u001b[0;32m     14\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m123\u001b[39m, \u001b[38;5;241m456\u001b[39m, \u001b[38;5;241m789\u001b[39m]  \u001b[38;5;66;03m# Remplacez par vos étiquettes encodées\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[1;34m(image_paths, labels)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m image_paths:\n\u001b[0;32m      4\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m----> 5\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Redimensionner à 100x30 pixels\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     img \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalisation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     images\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(image_paths, labels):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (100, 30))  # Redimensionner à 100x30 pixels\n",
    "        img = img / 255.0  # Normalisation\n",
    "        images.append(img)\n",
    "    images = np.array(images).reshape(-1, 30, 100, 1)  # Ajouter la dimension des canaux\n",
    "    labels = to_categorical(labels, num_classes=36)  # 36 classes (0-9, A-Z)\n",
    "    return train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Exemple de données (à remplacer par le dataset ANPR réel)\n",
    "image_paths = [\"ANPR/plate1.jpg\", \"ANPR/plate2.jpg\", \"ANPR/plate3.jpg\"]  # Remplacez par vos chemins\n",
    "labels = [123, 456, 789]  # Remplacez par vos étiquettes encodées\n",
    "X_train, X_test, y_train, y_test = load_and_preprocess_data(image_paths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Architecture CNN avec 10 couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(30, 100, 1)),  # Couche 1\n",
    "    MaxPooling2D((2, 2)),  # Couche 2\n",
    "    Conv2D(32, (3, 3), activation='relu'),  # Couche 3\n",
    "    MaxPooling2D((2, 2)),  # Couche 4\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Couche 5\n",
    "    Conv2D(64, (3, 3), activation='relu'),  # Couche 6\n",
    "    MaxPooling2D((2, 2)),  # Couche 7\n",
    "    Flatten(),  # Couche 8\n",
    "    Dense(128, activation='relu'),  # Couche 9\n",
    "    Dropout(0.5),  # Couche 10\n",
    "    Dense(36, activation='softmax')  # Sortie\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reconnaissance des plaques (sans YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_plate(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (100, 30))\n",
    "    gray = gray / 255.0\n",
    "    gray = np.expand_dims(gray, axis=(0, -1))\n",
    "    prediction = model.predict(gray)\n",
    "    char_indices = np.argmax(prediction, axis=1)\n",
    "    chars = [chr(ord('0') + i) if i < 10 else chr(ord('A') + i - 10) for i in char_indices]\n",
    "    plate_text = ''.join(chars)\n",
    "    return plate_text\n",
    "\n",
    "# Exemple avec une vidéo\n",
    "cap = cv2.VideoCapture(\"TEST.mp4\")\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_cnn.mp4', fourcc, fps, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "start_time = datetime.now()\n",
    "license_plates = set()\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    print(f\"Frame Number: {count}\")\n",
    "    plate_text = recognize_plate(frame)\n",
    "    if plate_text:\n",
    "        license_plates.add(plate_text)\n",
    "        cv2.putText(frame, plate_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    out.write(frame)\n",
    "    cv2.imshow(\"ANPR with CNN\", frame)\n",
    "    current_time = datetime.now()\n",
    "    if (current_time - start_time).seconds >= 20:\n",
    "        save_to_database(license_plates, start_time, current_time)\n",
    "        start_time = current_time\n",
    "        license_plates.clear()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sauvegarde dans la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_database(license_plates, start_time, end_time):\n",
    "    conn = sqlite3.connect('licencePlates.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('CREATE TABLE IF NOT EXISTS LicencesPlates (id INTEGER PRIMARY KEY AUTOINCREMENT, start_time TEXT, end_time TEXT, licence_plate TEXT)')\n",
    "    for plate in license_plates:\n",
    "        cursor.execute('INSERT INTO LicencesPlates (start_time, end_time, licence_plate) VALUES (?, ?, ?)', (start_time.isoformat(), end_time.isoformat(), plate))\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Évaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
